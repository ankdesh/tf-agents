{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klGNgWREsvQv"
   },
   "source": [
    "##### Copyright 2018 The TF-Agents Authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lsaQlK8fFQqH"
   },
   "source": [
    "### Get Started\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/agents/blob/master/tf_agents/colabs/1_dqn_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/agents/blob/master/tf_agents/colabs/1_dqn_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KEHR2Ui-lo8O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Collecting gym==0.10.11\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/04/70d4901b7105082c9742acd64728342f6da7cd471572fd0660a73f9cfe27/gym-0.10.11.tar.gz (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 5.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting scipy (from gym==0.10.11)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/30/526bee2ce18c066f9ff13ba89603f6c2b96c9fd406b57a21a7ba14bf5679/scipy-1.2.1-cp35-cp35m-manylinux1_x86_64.whl (24.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.7MB 1.1MB/s ta 0:00:011   53% |█████████████████               | 13.2MB 3.9MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from gym==0.10.11) (1.16.2)\n",
      "Collecting requests>=2.0 (from gym==0.10.11)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 7.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from gym==0.10.11) (1.12.0)\n",
      "Collecting pyglet>=1.2.0 (from gym==0.10.11)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 2.3MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting urllib3<1.25,>=1.21.1 (from requests>=2.0->gym==0.10.11)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/00/ee1d7de624db8ba7090d1226aebefab96a2c71cd5cfa7629d6ad3f61b79e/urllib3-1.24.1-py2.py3-none-any.whl (118kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 416kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting idna<2.9,>=2.5 (from requests>=2.0->gym==0.10.11)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 2.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests>=2.0->gym==0.10.11)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/75/f692a584e85b7eaba0e03827b3d51f45f571c2e793dd731e598828d380aa/certifi-2019.3.9-py2.py3-none-any.whl (158kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 966kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests>=2.0->gym==0.10.11)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 1.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting future (from pyglet>=1.2.0->gym==0.10.11)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/52/e20466b85000a181e1e144fd8305caf2cf475e2f9674e797b222f8105f5f/future-0.17.1.tar.gz (829kB)\n",
      "\u001b[K    100% |████████████████████████████████| 829kB 1.6MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: gym, future\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ankdesh/.cache/pip/wheels/7b/eb/1f/22c4124f3c64943aa0646daf4612b1c1f00f27d89b81304ebd\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ankdesh/.cache/pip/wheels/0c/61/d2/d6b7317325828fbb39ee6ad559dbe4664d0896da4721bf379e\n",
      "Successfully built gym future\n",
      "Installing collected packages: scipy, urllib3, idna, certifi, chardet, requests, future, pyglet, gym\n",
      "Successfully installed certifi-2019.3.9 chardet-3.0.4 future-0.17.1 gym-0.10.11 idna-2.8 pyglet-1.3.2 requests-2.21.0 scipy-1.2.1 urllib3-1.24.1\n",
      "Collecting imageio\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0a/943c965d372dae0b1f1482677d29030ab834351a61a9a632fd62f27f1523/imageio-2.5.0-py3-none-any.whl (3.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.3MB 2.9MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting pillow (from imageio)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/e9/5c47710fe383f0582da668302a80a6355fe15c2ce2dde89b50fe34acefa6/Pillow-5.4.1-cp35-cp35m-manylinux1_x86_64.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 2.4MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from imageio) (1.16.2)\n",
      "Installing collected packages: pillow, imageio\n",
      "Successfully installed imageio-2.5.0 pillow-5.4.1\n",
      "Requirement already satisfied: PILLOW in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (5.4.1)\n",
      "Requirement already satisfied: pyglet in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (1.3.2)\n",
      "Requirement already satisfied: future in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from pyglet) (0.17.1)\n",
      "Collecting pyvirtualdisplay\n",
      "  Downloading https://files.pythonhosted.org/packages/39/37/f285403a09cc261c56b6574baace1bdcf4b8c7428c8a7239cbba137bc0eb/PyVirtualDisplay-0.2.1.tar.gz\n",
      "Collecting EasyProcess (from pyvirtualdisplay)\n",
      "  Downloading https://files.pythonhosted.org/packages/45/3a/4eecc0c7995a13a64739bbedc0d3691fc574245b7e79cff81905aa0c2b38/EasyProcess-0.2.5.tar.gz\n",
      "Building wheels for collected packages: pyvirtualdisplay, EasyProcess\n",
      "  Building wheel for pyvirtualdisplay (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ankdesh/.cache/pip/wheels/d1/8c/16/1c64227974ae29c687e4cc30fd691d5c0fd40f54446dde99da\n",
      "  Building wheel for EasyProcess (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ankdesh/.cache/pip/wheels/41/22/19/af15ef6264c58b625a82641ed7483ad05e258fbd8925505227\n",
      "Successfully built pyvirtualdisplay EasyProcess\n",
      "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
      "Successfully installed EasyProcess-0.2.5 pyvirtualdisplay-0.2.1\n",
      "Requirement already satisfied: tf-agents-nightly in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (0.2.0.dev20190321)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-agents-nightly) (1.16.2)\n",
      "Collecting tfp-nightly==0.7.0.dev20190304 (from tf-agents-nightly)\n",
      "  Using cached https://files.pythonhosted.org/packages/aa/41/1f21a53cfbde6c132c487e2db37571fd2951d667a58086efcb9996280b0f/tfp_nightly-0.7.0.dev20190304-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-agents-nightly) (1.12.0)\n",
      "Requirement already satisfied: gin-config==0.1.3 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-agents-nightly) (0.1.3)\n",
      "Requirement already satisfied: absl-py>=0.6.1 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-agents-nightly) (0.7.1)\n",
      "Installing collected packages: tfp-nightly\n",
      "  Found existing installation: tfp-nightly 0.7.0.dev20190329\n",
      "    Uninstalling tfp-nightly-0.7.0.dev20190329:\n",
      "      Successfully uninstalled tfp-nightly-0.7.0.dev20190329\n",
      "Successfully installed tfp-nightly-0.7.0.dev20190304\n",
      "Collecting tf-nightly\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/2f/9c005cbc0d2e2f1420aba74cd182d0cb1349baf3f9fa4c63347b89ab3a9a/tf_nightly-1.14.1.dev20190329-cp35-cp35m-manylinux1_x86_64.whl (103.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 103.0MB 581kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-nightly) (1.16.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-nightly) (0.7.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-nightly) (1.0.9)\n",
      "Requirement already satisfied: tf-estimator-nightly in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-nightly) (1.14.0.dev2019032901)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-nightly) (0.33.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-nightly) (1.0.7)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-nightly) (3.7.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.2 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-nightly) (0.1.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-nightly) (1.12.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-nightly) (0.2.2)\n",
      "Requirement already satisfied: tb-nightly<1.15.0a0,>=1.14.0a0 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-nightly) (1.14.0a20190319)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-nightly) (0.7.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tf-nightly) (1.19.0)\n",
      "Requirement already satisfied: h5py in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from keras-applications>=1.0.6->tf-nightly) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from protobuf>=3.6.1->tf-nightly) (40.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly) (0.15.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ankdesh/virtualenvs/tf_agents/lib/python3.5/site-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly) (3.1)\n",
      "Installing collected packages: tf-nightly\n",
      "Successfully installed tf-nightly-1.14.1.dev20190329\n"
     ]
    }
   ],
   "source": [
    "# Note: If you haven't installed the following dependencies, run:\n",
    "!apt-get install xvfb\n",
    "!pip install 'gym==0.10.11'\n",
    "!pip install imageio\n",
    "!pip install PILLOW\n",
    "!pip install pyglet\n",
    "!pip install pyvirtualdisplay\n",
    "!pip install tf-agents-nightly\n",
    "!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZOUOQOrFs3zn"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKOCZlhUgXVK"
   },
   "source": [
    "This example shows how to train a [DQN (Deep Q Networks)](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)  agent on the Cartpole environment using the TF-Agents library.\n",
    "\n",
    "![Cartpole environment](images/cartpole.png)\n",
    "\n",
    "We will walk you through all the components in a Reinforcement Learning (RL) pipeline for training, evaluation and data collection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1u9QVVsShC9X"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sMitx5qSgJk1"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.agents.dqn import q_network\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import trajectory\n",
    "from tf_agents.metrics import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.utils import common\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "\n",
    "# Set up a virtual display for rendering OpenAI gym environments.\n",
    "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LmC0NDhdLIKY"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HC1kNrOsLSIZ"
   },
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v0'  # @param\n",
    "num_iterations = 20000  # @param\n",
    "\n",
    "initial_collect_steps = 1000  # @param\n",
    "collect_steps_per_iteration = 1  # @param\n",
    "replay_buffer_capacity = 100000  # @param\n",
    "\n",
    "fc_layer_params = (100,)\n",
    "\n",
    "batch_size = 64  # @param\n",
    "learning_rate = 1e-3  # @param\n",
    "log_interval = 200  # @param\n",
    "\n",
    "num_eval_episodes = 10  # @param\n",
    "eval_interval = 1000  # @param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMsJC3DEgI0x"
   },
   "source": [
    "## Environment\n",
    "\n",
    "Environments in RL represent the task or problem that we are trying to solve. Standard environments can be easily created in TF-Agents using `suites`. We have different `suites` for loading environments from sources such as the OpenAI Gym, Atari, DM Control, etc., given a string environment name.\n",
    "\n",
    "Now let us load the CartPole environment from the OpenAI Gym suite. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pYEz-S9gEv2-"
   },
   "outputs": [],
   "source": [
    "env = suite_gym.load(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IIHYVBkuvPNw"
   },
   "source": [
    "We can render this environment to see how it looks. A free-swinging pole is attached to a cart.  The goal is to move the cart right or left in order to keep the pole pointing up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RlO7WIQHu_7D"
   },
   "outputs": [
    {
     "ename": "ReraisedException",
     "evalue": "Error occured while running `from pyglet.gl import *`\nThe original exception was:\n\nImportError: Library \"GLU\" not found.\n\nHINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \"-screen 0 1400x900x24\" python <your_script.py>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReraisedException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e804510cb186>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@test {\"skip\": true}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/tf_agents/environments/wrappers.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/tf_agents/environments/wrappers.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error occured while running `from pyglet.gl import *`\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \\\"-screen 0 1400x900x24\\\" python <your_script.py>'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/gym/utils/reraise.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(prefix, suffix)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReraisedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_exc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mreraise_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# http://stackoverflow.com/a/13653312\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/gym/utils/reraise_impl_py3.py\u001b[0m in \u001b[0;36mreraise_impl\u001b[0;34m(e, traceback)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# semi-smart exception chaining, which we don't want in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreraise_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error occured while running `from pyglet.gl import *`\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \\\"-screen 0 1400x900x24\\\" python <your_script.py>'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'$Id$'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGLException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/pyglet/gl/lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib_agl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlink_GL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_GLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_AGL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib_glx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlink_GL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_GLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_GLX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/pyglet/gl/lib_glx.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mgl_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mglu_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GLU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Look for glXGetProcAddressARB extension, use it as fallback (for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/pyglet/lib.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, *names, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Library \"%s\" not found.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mfind_library\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mReraisedException\u001b[0m: Error occured while running `from pyglet.gl import *`\nThe original exception was:\n\nImportError: Library \"GLU\" not found.\n\nHINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \"-screen 0 1400x900x24\" python <your_script.py>'"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "env.reset()\n",
    "PIL.Image.fromarray(env.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9_lskPOey18"
   },
   "source": [
    "The `time_step = environment.step(action)` statement takes `action` in the environment.  The `TimeStep` tuple returned contains the environment's next observation and reward for that action. The `time_step_spec()` and `action_spec()` methods in the environment return the specifications (types, shapes, bounds) of the `time_step` and `action` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exDv57iHfwQV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec:\n",
      "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name=None, minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])\n",
      "Action Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name=None, minimum=0, maximum=1)\n"
     ]
    }
   ],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)\n",
    "print('Action Spec:')\n",
    "print(env.action_spec())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eJCgJnx3g0yY"
   },
   "source": [
    "So, we see that observation is an array of 4 floats: the position and velocity of the cart, and the angular position and velocity of the pole. Since only two actions are possible (move left or move right), the `action_spec` is a scalar where 0 means \"move left\" and 1 means \"move right.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2UGR5t_iZX-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step:\n",
      "TimeStep(step_type=array(0, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([-0.04244399,  0.02494707,  0.03707486, -0.02356851], dtype=float32))\n",
      "Next time step:\n",
      "TimeStep(step_type=array(1, dtype=int32), reward=array(1., dtype=float32), discount=array(1., dtype=float32), observation=array([-0.04194504,  0.21951826,  0.03660349, -0.30432722], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "time_step = env.reset()\n",
    "print('Time step:')\n",
    "print(time_step)\n",
    "\n",
    "action = 1\n",
    "\n",
    "next_time_step = env.step(action)\n",
    "print('Next time step:')\n",
    "print(next_time_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zuUqXAVmecTU"
   },
   "source": [
    "Usually we create two environments: one for training and one for evaluation. Most environments are written in pure python, but they can be easily converted to TensorFlow using the `TFPyEnvironment` wrapper. The original environment's API uses numpy arrays, the `TFPyEnvironment` converts these to/from `Tensors` for you to more easily interact with TensorFlow policies and agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xp-Y4mD6eDhF"
   },
   "outputs": [],
   "source": [
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E9lW_OZYFR8A"
   },
   "source": [
    "## Agent\n",
    "\n",
    "The algorithm that we use to solve an RL problem is represented as an `Agent`. In addition to the DQN agent, TF-Agents provides standard implementations of a variety of `Agents` such as [REINFORCE](http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf), [DDPG](https://arxiv.org/pdf/1509.02971.pdf), [TD3](https://arxiv.org/pdf/1802.09477.pdf), [PPO](https://arxiv.org/abs/1707.06347) and [SAC](https://arxiv.org/abs/1801.01290).\n",
    "\n",
    "The DQN agent can be used in any environment which has a discrete action space. To create a DQN Agent, we first need a `Q-Network` that can learn to predict `Q-Values` (expected return) for all actions given an observation from the environment. \n",
    "\n",
    "We can easily create a `Q-Network` using the specs of the observations and actions. We can specify the layers in the network which, in this example, is the `fc_layer_params` argument set to a tuple of `ints` representing the sizes of each hidden layer (see the Hyperparameters section above).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TgkdEPg_muzV"
   },
   "outputs": [],
   "source": [
    "q_net = q_network.QNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z62u55hSmviJ"
   },
   "source": [
    "We also need an `optimizer` to train the network we just created, and a `train_step_counter` variable to keep track of how many times the network was updated.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbY4yrjTEyc9"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.compat.v2.Variable(0)\n",
    "\n",
    "tf_agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=dqn_agent.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "tf_agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I0KLrEPwkn5x"
   },
   "source": [
    "## Policies\n",
    "\n",
    "In TF-Agents, policies represent the standard notion of policies in RL: given a `time_step` produce an action or a distribution over actions. The main method is `policy_step = policy.step(time_step)` where `policy_step` is a named tuple `PolicyStep(action, state, info)`.  The `policy_step.action` is the `action` to be applied to the environment, `state` represents the state for stateful (RNN) policies and `info` may contain auxiliary information such as log probabilities of the actions. \n",
    "\n",
    "Agents contain two policies: the main policy that is used for evaluation/deployment (agent.policy) and another policy that is used for data collection (agent.collect_policy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BwY7StuMkuV4"
   },
   "outputs": [],
   "source": [
    "eval_policy = tf_agent.policy\n",
    "collect_policy = tf_agent.collect_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d5a04gY_rD_a"
   },
   "source": [
    "We can also independently create policies that are not part of an agent. For example, a random policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HE37-UCIrE69"
   },
   "outputs": [],
   "source": [
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "94rCXQtbUbXv"
   },
   "source": [
    "## Metrics and Evaluation\n",
    "\n",
    "The most common metric used to evaluate a policy is the average return. The return is the sum of rewards obtained while running a policy in an environment for an episode, and we usually average this over a few episodes. We can compute the average return metric as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bitzHo5_UbXy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)\n",
    "\n",
    "# Please also see the metrics module for standard implementations of different\n",
    "# metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NLva6g2jdWgr"
   },
   "source": [
    "## Replay Buffer\n",
    "\n",
    "In order to keep track of the data collected from the environment, we will use the TFUniformReplayBuffer. This replay buffer is constructed using specs describing the tensors that are to be stored, which can be obtained from the agent using `tf_agent.collect_data_spec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vX2zGUWJGWAl"
   },
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=tf_agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZGNTDJpZs4NN"
   },
   "source": [
    "For most agents, the `collect_data_spec` is a `Trajectory` named tuple containing the observation, action, reward etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rVD5nQ9ZGo8_"
   },
   "source": [
    "## Data Collection\n",
    "\n",
    "Now let us execute the random policy in the environment for a few steps and record the data (observations, actions, rewards etc) in the replay buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wr1KSAEGG4h9"
   },
   "outputs": [],
   "source": [
    "#@test {\"skip\": true}\n",
    "def collect_step(environment, policy):\n",
    "  time_step = environment.current_time_step()\n",
    "  action_step = policy.action(time_step)\n",
    "  next_time_step = environment.step(action_step.action)\n",
    "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "  # Add trajectory to the replay buffer\n",
    "  replay_buffer.add_batch(traj)\n",
    "\n",
    "\n",
    "for _ in range(initial_collect_steps):\n",
    "  collect_step(train_env, random_policy)\n",
    "\n",
    "# This loop is so common in RL, that we provide standard implementations of\n",
    "# these. For more details see the drivers module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TujU-PMUsKjS"
   },
   "source": [
    "In order to sample data from the replay buffer, we will create a `tf.data` pipeline which we can feed to the agent for training later. We can specify the `sample_batch_size` to configure the number of items sampled from the replay buffer. We can also optimize the data pipline using parallel calls and prefetching.\n",
    "\n",
    "In order to save space, we only store the current observation in each row of the replay buffer. But since the DQN Agent needs both the current and next observation to compute the loss, we always sample two adjacent rows for each item in the batch by setting `num_steps=2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ba7bilizt_qW"
   },
   "outputs": [],
   "source": [
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, sample_batch_size=batch_size, num_steps=2).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBc9lj9VWWtZ"
   },
   "source": [
    "## Training the agent\n",
    "\n",
    "The training loop involves both collecting data from the environment and optimizing the agent's networks. Along the way, we will occasionally evaluate the agent's policy to see how we are doing.\n",
    "\n",
    "The following will take ~5 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0pTbJ3PeyF-u",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 200: loss = 13.795380592346191\n",
      "step = 400: loss = 17.001819610595703\n",
      "step = 600: loss = 23.203895568847656\n",
      "step = 800: loss = 63.41914367675781\n",
      "step = 1000: loss = 25.145221710205078\n",
      "step = 1000: Average Return = 76.30000305175781\n",
      "step = 1200: loss = 30.940677642822266\n",
      "step = 1400: loss = 98.54993438720703\n",
      "step = 1600: loss = 88.28910064697266\n",
      "step = 1800: loss = 148.22213745117188\n",
      "step = 2000: loss = 18.388916015625\n",
      "step = 2000: Average Return = 40.79999923706055\n",
      "step = 2200: loss = 62.94413757324219\n",
      "step = 2400: loss = 55.6567268371582\n",
      "step = 2600: loss = 36.198123931884766\n",
      "step = 2800: loss = 7.448940277099609\n",
      "step = 3000: loss = 36.054710388183594\n",
      "step = 3000: Average Return = 44.79999923706055\n",
      "step = 3200: loss = 142.97750854492188\n",
      "step = 3400: loss = 49.81282424926758\n",
      "step = 3600: loss = 60.743385314941406\n",
      "step = 3800: loss = 45.471832275390625\n",
      "step = 4000: loss = 6.750802993774414\n",
      "step = 4000: Average Return = 42.900001525878906\n",
      "step = 4200: loss = 48.01283264160156\n",
      "step = 4400: loss = 10.83920955657959\n",
      "step = 4600: loss = 88.84729766845703\n",
      "step = 4800: loss = 65.919189453125\n",
      "step = 5000: loss = 70.64014434814453\n",
      "step = 5000: Average Return = 67.69999694824219\n",
      "step = 5200: loss = 55.836021423339844\n",
      "step = 5400: loss = 73.03237915039062\n",
      "step = 5600: loss = 107.57528686523438\n",
      "step = 5800: loss = 67.40693664550781\n",
      "step = 6000: loss = 182.3212890625\n",
      "step = 6000: Average Return = 84.9000015258789\n",
      "step = 6200: loss = 43.765560150146484\n",
      "step = 6400: loss = 11.50094985961914\n",
      "step = 6600: loss = 93.3211669921875\n",
      "step = 6800: loss = 11.838296890258789\n",
      "step = 7000: loss = 193.87184143066406\n",
      "step = 7000: Average Return = 139.8000030517578\n",
      "step = 7200: loss = 12.473770141601562\n",
      "step = 7400: loss = 277.53277587890625\n",
      "step = 7600: loss = 21.229759216308594\n",
      "step = 7800: loss = 29.24190330505371\n",
      "step = 8000: loss = 12.60224437713623\n",
      "step = 8000: Average Return = 200.0\n",
      "step = 8200: loss = 144.09268188476562\n",
      "step = 8400: loss = 209.81793212890625\n",
      "step = 8600: loss = 502.037109375\n",
      "step = 8800: loss = 119.23500061035156\n",
      "step = 9000: loss = 170.40879821777344\n",
      "step = 9000: Average Return = 195.1999969482422\n",
      "step = 9200: loss = 219.3653564453125\n",
      "step = 9400: loss = 14.828374862670898\n",
      "step = 9600: loss = 19.17943572998047\n",
      "step = 9800: loss = 227.9813690185547\n",
      "step = 10000: loss = 20.411922454833984\n",
      "step = 10000: Average Return = 200.0\n",
      "step = 10200: loss = 688.5272827148438\n",
      "step = 10400: loss = 314.7534484863281\n",
      "step = 10600: loss = 255.23260498046875\n",
      "step = 10800: loss = 549.0745849609375\n",
      "step = 11000: loss = 82.64981079101562\n",
      "step = 11000: Average Return = 200.0\n",
      "step = 11200: loss = 29.89480209350586\n",
      "step = 11400: loss = 361.3161926269531\n",
      "step = 11600: loss = 752.6821899414062\n",
      "step = 11800: loss = 251.7952423095703\n",
      "step = 12000: loss = 638.88720703125\n",
      "step = 12000: Average Return = 199.0\n",
      "step = 12200: loss = 94.25526428222656\n",
      "step = 12400: loss = 29.437482833862305\n",
      "step = 12600: loss = 625.7532958984375\n",
      "step = 12800: loss = 791.6722412109375\n",
      "step = 13000: loss = 906.277587890625\n",
      "step = 13000: Average Return = 200.0\n",
      "step = 13200: loss = 31.088754653930664\n",
      "step = 13400: loss = 470.5264892578125\n",
      "step = 13600: loss = 41.11328125\n",
      "step = 13800: loss = 1896.6593017578125\n",
      "step = 14000: loss = 1659.1129150390625\n",
      "step = 14000: Average Return = 200.0\n",
      "step = 14200: loss = 597.581787109375\n",
      "step = 14400: loss = 873.250732421875\n",
      "step = 14600: loss = 879.7315063476562\n",
      "step = 14800: loss = 2985.62353515625\n",
      "step = 15000: loss = 1838.82470703125\n",
      "step = 15000: Average Return = 200.0\n",
      "step = 15200: loss = 90.81114959716797\n",
      "step = 15400: loss = 2731.179443359375\n",
      "step = 15600: loss = 1348.401123046875\n",
      "step = 15800: loss = 1280.5911865234375\n",
      "step = 16000: loss = 70.04158782958984\n",
      "step = 16000: Average Return = 200.0\n",
      "step = 16200: loss = 123.47377014160156\n",
      "step = 16400: loss = 1788.759521484375\n",
      "step = 16600: loss = 7509.3349609375\n",
      "step = 16800: loss = 678.5142822265625\n",
      "step = 17000: loss = 63.76680374145508\n",
      "step = 17000: Average Return = 200.0\n",
      "step = 17200: loss = 1048.10107421875\n",
      "step = 17400: loss = 302.7504577636719\n",
      "step = 17600: loss = 87.77569580078125\n",
      "step = 17800: loss = 6785.6962890625\n",
      "step = 18000: loss = 91.79792022705078\n",
      "step = 18000: Average Return = 200.0\n",
      "step = 18200: loss = 146.93307495117188\n",
      "step = 18400: loss = 112.84071350097656\n",
      "step = 18600: loss = 3202.037109375\n",
      "step = 18800: loss = 122.44189453125\n",
      "step = 19000: loss = 400.7648620605469\n",
      "step = 19000: Average Return = 200.0\n",
      "step = 19200: loss = 129.54629516601562\n",
      "step = 19400: loss = 173.32479858398438\n",
      "step = 19600: loss = 1497.4984130859375\n",
      "step = 19800: loss = 2236.068603515625\n",
      "step = 20000: loss = 4199.72509765625\n",
      "step = 20000: Average Return = 200.0\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "#%%time\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "tf_agent.train = common.function(tf_agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "tf_agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, tf_agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  for _ in range(collect_steps_per_iteration):\n",
    "    collect_step(train_env, tf_agent.collect_policy)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = tf_agent.train(experience)\n",
    "\n",
    "  step = tf_agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, tf_agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "68jNcA_TiJDq"
   },
   "source": [
    "## Visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aO-LWCdbbOIC"
   },
   "source": [
    "### Plots\n",
    "\n",
    "We can plot return vs global steps to see the performance of our agent. In `Cartpole-v0`, the environment gives a reward of +1 for every time step the pole stays up, and since the maximum number of steps is 200, the maximum possible return is also 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxtL1mbOYCVO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.4300004005432125, 250)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "\n",
    "steps = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(steps, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Step')\n",
    "plt.ylim(top=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7-XpPP99Cy7"
   },
   "source": [
    "### Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9pGfGxSH32gn"
   },
   "source": [
    "It is helpful to visualize the performance of an agent by rendering the environment at each step. Before we do that, let us first create a function to embed videos in this colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULaGr8pvOKbl"
   },
   "outputs": [],
   "source": [
    "def embed_mp4(filename):\n",
    "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "  video = open(filename,'rb').read()\n",
    "  b64 = base64.b64encode(video)\n",
    "  tag = '''\n",
    "  <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "  </video>'''.format(b64.decode())\n",
    "\n",
    "  return IPython.display.HTML(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9c_PH-pX4Pr5"
   },
   "source": [
    "The following code visualizes the agent's policy for a few episodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owOVWB158NlF"
   },
   "outputs": [
    {
     "ename": "ReraisedException",
     "evalue": "Error occured while running `from pyglet.gl import *`\nThe original exception was:\n\nImportError: Library \"GLU\" not found.\n\nHINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \"-screen 0 1400x900x24\" python <your_script.py>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReraisedException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8a8587ed06c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtime_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_py_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_last\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0maction_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/tf_agents/environments/wrappers.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/tf_agents/environments/wrappers.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error occured while running `from pyglet.gl import *`\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \\\"-screen 0 1400x900x24\\\" python <your_script.py>'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/gym/utils/reraise.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(prefix, suffix)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReraisedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_exc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mreraise_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# http://stackoverflow.com/a/13653312\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/gym/utils/reraise_impl_py3.py\u001b[0m in \u001b[0;36mreraise_impl\u001b[0;34m(e, traceback)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# semi-smart exception chaining, which we don't want in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreraise_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error occured while running `from pyglet.gl import *`\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \\\"-screen 0 1400x900x24\\\" python <your_script.py>'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'$Id$'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGLException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/pyglet/gl/lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib_agl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlink_GL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_GLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_AGL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib_glx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlink_GL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_GLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_GLX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/pyglet/gl/lib_glx.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mgl_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mglu_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GLU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Look for glXGetProcAddressARB extension, use it as fallback (for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tf_agents/lib/python3.5/site-packages/pyglet/lib.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, *names, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Library \"%s\" not found.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mfind_library\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mReraisedException\u001b[0m: Error occured while running `from pyglet.gl import *`\nThe original exception was:\n\nImportError: Library \"GLU\" not found.\n\nHINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \"-screen 0 1400x900x24\" python <your_script.py>'"
     ]
    }
   ],
   "source": [
    "num_episodes = 3\n",
    "video_filename = 'imageio.mp4'\n",
    "with imageio.get_writer(video_filename, fps=60) as video:\n",
    "  for _ in range(num_episodes):\n",
    "    time_step = eval_env.reset()\n",
    "    video.append_data(eval_py_env.render())\n",
    "    while not time_step.is_last():\n",
    "      action_step = tf_agent.policy.action(time_step)\n",
    "      time_step = eval_env.step(action_step.action)\n",
    "      video.append_data(eval_py_env.render())\n",
    "\n",
    "embed_mp4(video_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "name": "DQN Tutorial.ipynb",
   "provenance": [
    {
     "file_id": "1tL_oyGKGsHmtpK056cVQteeadnpaHAtq",
     "timestamp": 1551337271702
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
